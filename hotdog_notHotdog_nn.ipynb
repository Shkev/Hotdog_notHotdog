{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hotdog_notHotdog_nn",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shkev/Hotdog_notHotdog/blob/master/hotdog_notHotdog_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEIXRwNMt0B-",
        "colab_type": "text"
      },
      "source": [
        "#Hotdot Not Hotdog Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pr25v88tGdVS",
        "colab_type": "code",
        "outputId": "6e99bd2b-0be1-4e22-d504-3bacffea2941",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n",
        "except ValueError: # If TPU not found\n",
        "  tpu = None\n",
        "  \n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "print('Running on TPU ', tpu.cluster_spec().as_dict()['worker']) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system.\n",
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "Running on TPU  ['10.22.114.26:8470']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzUwmIt5tm5C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.contrib import tpu\n",
        "from tensorflow.contrib.cluster_resolver import TPUClusterResolver\n",
        "from tensorflow.contrib.tpu.python.tpu import tpu_function\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "tpu_cluster = TPUClusterResolver(\n",
        "    tpu=[tpu_address]).get_master()\n",
        "\n",
        "tpu_function.get_tpu_context().set_number_of_shards(8)\n",
        "\n",
        "#hyperparam\n",
        "training_iterations = 50\n",
        "\n",
        "PATH = \"/content/drive/My Drive/Colab Notebooks/ML/Hotdog_notHotdog/trainingDataHotDog\"\n",
        "validation_path = \"/content/drive/My Drive/Colab Notebooks/ML/Hotdog_notHotdog/validationDataHotDog\"\n",
        "saver_path = \"/content/drive/My Drive/Colab Notebooks/ML/Hotdog_notHotdog/Saved_Model_Checkpoint/nn_model.ckpt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uiq0KjQm2JKh",
        "colab_type": "text"
      },
      "source": [
        "##Defining All Functions\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Label Creation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evMEcDBa2QQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def y_labels(index):\n",
        "    return tf.one_hot([index], 3)     #creates one_hot encoding for data; tensor size = (# of elements in index) x (depth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF4z0YU92kTJ",
        "colab_type": "text"
      },
      "source": [
        "Importing Data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qspuNg9K2j7Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def import_data(image_path):\n",
        "  image_contents = tf.read_file(filename=image_path)   #reads image file\n",
        "  modified_image = tf.image.decode_jpeg(contents=image_contents, channels=1)   #decodes jpeg image to tensor (uint8)\n",
        "  cropped_and_modified_image_tensor = tf.image.resize_with_crop_or_pad(modified_image, 100, 100)   #resizes image\n",
        "  image_tensor = tf.cast(tf.reshape(cropped_and_modified_image_tensor, [1, 10000]), dtype=tf.float32)   #casts reshaped modified image tensor as a float32\n",
        "  return image_tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksD2XpHA30cL",
        "colab_type": "text"
      },
      "source": [
        "###**Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlM9FO7I3z23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def neural_network(input_layer):\n",
        "  Weight_net_1 = {'weights': tf.Variable(tf.random_normal(shape=(10000, 32)), dtype=tf.float32, name=\"Weight1\"), 'bias': tf.Variable(tf.random_normal(shape=(1, 1)), dtype=tf.float32, name=\"Bias1\")}\n",
        "  Weight_net_2 = {'weights': tf.Variable(tf.random_normal(shape=(32, 16)), dtype=tf.float32, name=\"Weight2\"), 'bias': tf.Variable(tf.random_normal(shape=(1, 1)), dtype=tf.float32, name=\"Bias2\")}\n",
        "  Weight_net_3 = {'weights': tf.Variable(tf.random_normal(shape=(16, 3)), dtype=tf.float32, name=\"Weight3\"), 'bias': tf.Variable(tf.random_normal(shape=(1, 1)), dtype=tf.float32, name=\"Bias3\")}\n",
        "  #Weight_net_4 = {'weights': tf.Variable(tf.random_normal(shape=(16, 3)), dtype=tf.float32, name=\"Weight4\"), 'bias': tf.Variable(tf.random_normal(shape=(1, 1)), dtype=tf.float32, name=\"Bias4\")}\n",
        "  \n",
        "  #Input Layer\n",
        "  hypothesis = input_layer\n",
        "  #Hidden Layer 1\n",
        "  hypothesis = tf.nn.relu(tf.matmul(hypothesis, Weight_net_1['weights']) + Weight_net_1['bias'])\n",
        "  #Hidden Layer 2\n",
        "  hypothesis = tf.nn.relu(tf.matmul(hypothesis, Weight_net_2['weights']) + Weight_net_2['bias'])\n",
        "  #Hidden Layer 3\n",
        "  hypothesis = tf.nn.softmax(tf.matmul(hypothesis, Weight_net_3['weights']) + Weight_net_3['bias'])\n",
        "  #output cell\n",
        "  #hypothesis = tf.nn.softmax(tf.matmul(hypothesis, Weight_net_4['weights']) + Weight_net_4['bias'])\n",
        "  return hypothesis"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hXmfaPC5u-u",
        "colab_type": "text"
      },
      "source": [
        "##Running Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4KwJwnL6KkV",
        "colab_type": "text"
      },
      "source": [
        "Declaring Placeholders:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClU8Uwy-5y6X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = tf.placeholder(shape=[1, 10000], dtype=tf.float32, name='X')\n",
        "Y = tf.placeholder(shape=[1, 3], dtype=tf.float32, name='Y')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfliOE8S7V4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn = neural_network(input_layer=X)\n",
        "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=nn), name='cross_entropy')\n",
        "train = tf.contrib.tpu.CrossShardOptimizer(\n",
        "    tf.train.AdamOptimizer(1)).minimize(cross_entropy)  #minimizes cross entropy loss\n",
        "\n",
        "\n",
        "#to save nn object (saver function)\n",
        "#saver = tf.train.Saver(max_to_keep=1, name='saver')\n",
        "\n",
        "#to store sigmoid determinant\n",
        "sigmoid_determinant = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJGR4rgO80kb",
        "colab_type": "text"
      },
      "source": [
        "**Starting Session to run code:**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxH1i7Gt80TA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.Session(tpu_cluster) as sess:\n",
        "  sess.run(tpu.initialize_system())\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  sess.run(tf.local_variables_initializer())\n",
        "  #new_saver = tf.train.import_meta_graph(os.path.join(saver_path, 'nn_model.ckpt.meta'))\n",
        "  #new_saver.restore(sess, tf.train.latest_checkpoint(saver_path))  \n",
        "  for iteration in tqdm(range(training_iterations - 0), desc=\"COMPLETION\", ncols=80):\n",
        "    image_folder_dirs = [os.path.join(PATH, file_name) for file_name in os.listdir(PATH)]   #finding the number image folders\n",
        "    index_label = 0                          #setting the index labels to 0\n",
        "    for element in image_folder_dirs:        #the number of image_elements with in each of the image folders\n",
        "      label = sess.run(y_labels(index=index_label))     #creating the Y_labels for the network\n",
        "      image_tensor = sess.run(import_data(element))\n",
        "      sess.run(train, feed_dict={X:image_tensor, Y:label}) #begin training\n",
        "      index_label += 1     #incrementing number of labels\n",
        "    #saver.save(sess, saver_path, global_step=iteration)\n",
        "  \n",
        "  while 1:\n",
        "    validation_folder_dirs = [os.path.join(validation_path, file_name) for file_name in os.listdir(validation_path)]\n",
        "    for image in validation_folder_dirs:\n",
        "      validation_input = sess.run(import_data(image))\n",
        "      prediction = sess.run(nn, feed_dict={X:validation_input})\n",
        "      sigmoid = sess.run(tf.nn.sigmoid(prediction))\n",
        "      sigmoid.append(sigmoid_determinant)\n",
        "      \n",
        "      plt.ylabel('Sigmoid')\n",
        "      plt.xlabel('Iteration')\n",
        "      plt.title('Sigmoid Determinant vs. Iterations')\n",
        "      plt.tight_layout()\n",
        "      plt.plot(sigmoid_determinant, label='Validation')\n",
        "      \n",
        "  sess.run(tpu.shutdown_system())"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}